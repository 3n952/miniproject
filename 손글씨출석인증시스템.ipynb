{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNt7IHrhBVkoFc/Owjwr68X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#학번 숫자 인식 및 분류"],"metadata":{"id":"LjAMVCMr8quD"}},{"cell_type":"markdown","source":["#분류 모델"],"metadata":{"id":"LR-Frmx8q2AX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"opx0q1cXRXzz"},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","from google.colab.patches import cv2_imshow\n","%matplotlib inline "]},{"cell_type":"code","source":["(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"],"metadata":{"id":"89TBSQtpRhai","executionInfo":{"status":"ok","timestamp":1670968292573,"user_tz":-540,"elapsed":2105,"user":{"displayName":"김산","userId":"17362589598531284018"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e4e01c9b-ea5e-4897-cb18-c2e4a442c9ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 2s 0us/step\n"]}]},{"cell_type":"code","source":["#랜덤값 고정\n","tf.random.set_seed(1234)\n","\n","#normalize\n","X_train = X_train / 255.0\n","X_test = X_test / 255.0\n","\n","# reshape\n","X_train = X_train.reshape(-1, 28, 28, 1)\n","X_test = X_test.reshape(-1, 28, 28, 1)\n","\n","# one-hot 인코딩\n","y_train = tf.keras.utils.to_categorical(y_train, 10)\n","y_test = tf.keras.utils.to_categorical(y_test, 10)"],"metadata":{"id":"watvOakARkU7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 컴파일\n","cnn_model = tf.keras.Sequential([\n","    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, input_shape=(28,28,1), padding='same', activation='relu'), \n","    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n","    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n","\n","    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, input_shape=(28,28,1), padding='same', activation='relu'),\n","    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, input_shape=(28,28,1), padding='valid', activation='relu'),\n","    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n","\n","    tf.keras.layers.Flatten(),\n","    tf.keras.layers.Dense(units=512, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(units=256, activation='relu'),\n","    tf.keras.layers.Dropout(0.5),\n","    tf.keras.layers.Dense(units=10, activation='softmax')\n","])\n","cnn_model.compile(loss='categorical_crossentropy', optimizer= tf.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy'])"],"metadata":{"id":"HyQuq1Z7RtUL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#callback & early stopping 지점, 기준\n","checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only = True)\n","earlystopping_cb = tf.keras.callbacks.EarlyStopping(patience = 2, restore_best_weights=True)\n","\n","#모델 학습 + callback & early stopping\n","history = cnn_model.fit(X_train, y_train, batch_size=100, epochs=20, validation_data=(X_test, y_test), callbacks = [checkpoint_cb, earlystopping_cb])"],"metadata":{"id":"_eGaNBgVRy4A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#callback & early stopping한 지점까지 에포크 단위별 loss 시각화\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.xlabel('epoch')\n","plt.ylabel('loss')\n","plt.legend(['train', 'val'])\n","plt.show()"],"metadata":{"id":"kx5HipJ7SKcg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#모델 정확도 / 그래프 해석 예시: 그래프에서 보이듯이 epoch 5에서 가장 낮은 손실 점수 보여준다. (인덱스0부터 시작이므로 4는 5를 의미)\n","result = cnn_model.evaluate(X_test, y_test)\n","print(\"예측 정확도(%): \", result[1]*100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"g5bK_NOpSawP","executionInfo":{"status":"ok","timestamp":1670845626622,"user_tz":-540,"elapsed":2470,"user":{"displayName":"김산","userId":"17362589598531284018"}},"outputId":"e6d5c34b-b489-4ad6-93ce-6e9ddbbee417"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 [==============================] - 2s 4ms/step - loss: 0.0166 - accuracy: 0.9948\n","예측 정확도(%):  99.47999715805054\n"]}]},{"cell_type":"markdown","source":["#데이터베이스에 넣을 feature_vector값 구하기 (등록)"],"metadata":{"id":"NEObbmf8Sl5c"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.autograd import Variable\n","from PIL import Image\n","\n","# resnet적용\n","model = models.resnet18(pretrained=True)\n","\n","# avgpool layer 추출\n","layer = model._modules.get('avgpool')\n","\n","# 평가모드로 전환\n","model.eval()\n","\n","# 이미지 transform\n","scaler = transforms.Resize((224, 224))\n","normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","to_tensor = transforms.ToTensor()\n","\n","#특징 벡터 추출할 함수 선언\n","def get_vector(image_name):\n","  img = Image.open(image_name)\n","  t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)) #이미지 텐서변수에 할당\n","  my_embedding = torch.zeros(512) #특징 벡터가 들어갈 배열 초기화\n","  def copy_data(m, i, o): #특징벡터 복사 함수\n","    my_embedding.copy_(o.data.reshape(o.data.size(1))) \n","  h = layer.register_forward_hook(copy_data) #텐서변수 값 추출\n","  model(t_img) #resnet 모델에 적용\n","  h.remove() #초기화\n","  return my_embedding.numpy() #특징벡터를 넘파이배열로 바꿈\n","'''\n","  with open('/content/내학번샘플.jpg', 'rb') as fd:\n","    img = fd.read()\n","    img변수대신 넣기\n","'''"],"metadata":{"id":"WfbW5r7RSuNQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#학번 정수값 저장"],"metadata":{"id":"S5Ts6X8oORwS"}},{"cell_type":"code","source":["from google.colab import files\n","dbfile = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":215},"id":"Nzn8XiMprGdZ","executionInfo":{"status":"ok","timestamp":1670845664948,"user_tz":-540,"elapsed":26087,"user":{"displayName":"김산","userId":"17362589598531284018"}},"outputId":"8856b6b4-e15c-415b-e8a6-0fc7610ac79f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-8e01bab4-0ca8-4929-8097-275afdd1383c\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-8e01bab4-0ca8-4929-8097-275afdd1383c\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 1.jpg to 1.jpg\n","Saving 2.jpg to 2.jpg\n","Saving 내학번샘플3.jpg to 내학번샘플3.jpg\n","Saving 내학번샘플2.jpg to 내학번샘플2.jpg\n","Saving 내학번샘플.jpg to 내학번샘플.jpg\n"]}]},{"cell_type":"code","source":["img_db = cv2.imread('파일명')\n","\n","\n","img_db_gray = cv2.cvtColor(img_db, cv2.COLOR_BGR2GRAY)\n","img_db_blur = cv2.GaussianBlur(img_db_gray, (5, 5), 0)\n","\n","#이미지 내의 경계 찾기\n","ret_db,img_db_th = cv2.threshold(img_db_blur, 127, 255, cv2.THRESH_BINARY_INV)\n","contours_db, hierachy_db = cv2.findContours(img_db_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","\n","#경계 직사각형 찾기\n","rects_db = [cv2.boundingRect(each) for each in contours_db]\n","rects_db = sorted(rects_db)\n","\n","margin = 8\n","for rect in rects_db:\n","  print(rect)\n","  im1_db = cv2.rectangle(img_db_blur.copy(),(rect[0]-margin,rect[1]-margin),(rect[0]+rect[2]+margin, rect[1]+rect[3]+margin),(0,0,0),3)\n"],"metadata":{"id":"0Ey1pjtBjDGn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1670845735153,"user_tz":-540,"elapsed":4,"user":{"displayName":"김산","userId":"17362589598531284018"}},"outputId":"ad60745b-3862-4801-da7c-fe3fd1748b7e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(403, 328, 66, 75)\n","(514, 350, 42, 40)\n","(647, 326, 10, 76)\n","(740, 325, 47, 83)\n","(892, 323, 61, 73)\n","(1048, 316, 10, 105)\n","(1137, 313, 64, 92)\n","(1268, 314, 50, 78)\n","(1382, 309, 47, 93)\n"]}]},{"cell_type":"code","source":["#이전에 처리한 이미지 사용\n","img_for_class = img_db_blur.copy()\n","\n","#최종 이미지 파일용 배열\n","db_img = []\n","margin_pixel = margin\n","\n","#숫자영역 추출 및 reshape\n","for rect in rects_db:\n","  im = img_for_class[rect[1]-margin_pixel:rect[1]+rect[3]+margin_pixel, rect[0]-margin_pixel:rect[0]+rect[2]+margin_pixel]\n","  row, col = im.shape[:2]\n","  #정방형 비율 맞추기\n","  bordersize = max(row,col)\n","  diff = min(row,col)\n","  #이미지의 intensity 평균\n","  bottom = im[row-2: row, 0:col]\n","  mean = cv2.mean(bottom)[0]\n","  #정방형 비율로 보정\n","  border = cv2.copyMakeBorder(\n","      im, top =0, bottom =0,\n","      left = int((bordersize - diff) / 2),\n","      right = int ((bordersize - diff) / 2),\n","      borderType = cv2.BORDER_CONSTANT,\n","      value = [255, 255, 255]\n","  )\n","  square = border\n","\n","  #(28,28)로 축소\n","  resized_img = cv2.resize(square, dsize = (28, 28), interpolation = cv2.INTER_AREA)\n","  db_img.append(resized_img)"],"metadata":{"id":"D_ZmWWpNnPbo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res_index = []\n","\n","for i in range(len(db_img)):\n","  img = db_img[i]\n","  cv2_imshow(img)\n","  img = img.reshape(-1,28,28,1)\n","  input_data = ((np.array(img) / 255) - 1) * -1\n","  result = np.argmax(cnn_model.predict(input_data), axis = -1)\n","  res_index.append(int(result))\n","  print(result)\n","\n","res_index #학번 정수값 리스트"],"metadata":{"id":"WYbqW6HYEJ9u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#학번 번호별 이미지 저장 28*28크기\n","db_img"],"metadata":{"id":"PA84vGpApyiE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#학번 벡터값 저장"],"metadata":{"id":"rqrAqZDiOV-z"}},{"cell_type":"code","source":["'''\n","i = 1\n","print('db{0}.jpg'.format(i+1))\n","'''"],"metadata":{"id":"OzEW-5qGSwhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from PIL import Image\n","vector_list1 = [] #이미지가 리스트에 저장되어있다.\n","\n","for i in range(9):\n","  a = Image.fromarray(db_img[i])\n","  a.save('db{0}.jpg'.format(i+1)) \n","  vector_list1.append(a)\n"],"metadata":{"id":"aK25MYGZOnH8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#new data vector(인식)"],"metadata":{"id":"HmHfoBiJ5KaA"}},{"cell_type":"code","source":["img_new = cv2.imread('파일명')\n","\n","\n","img_new_gray = cv2.cvtColor(img_new, cv2.COLOR_BGR2GRAY)\n","img_new_blur = cv2.GaussianBlur(img_new_gray, (5, 5), 0)\n","\n","#이미지 내의 경계 찾기\n","ret_new,img_new_th = cv2.threshold(img_new_blur, 127, 255, cv2.THRESH_BINARY_INV)\n","contours_new, hierachy_new = cv2.findContours(img_new_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n","\n","#경계 직사각형 찾기\n","rects_new = [cv2.boundingRect(each) for each in contours_new]\n","rects_new = sorted(rects_new)\n","\n","margin = 8\n","for rect in rects_new:\n","  print(rect)\n","  im1_new = cv2.rectangle(img_new_blur.copy(),(rect[0]-margin,rect[1]-margin),(rect[0]+rect[2]+margin, rect[1]+rect[3]+margin),(0,0,0),3)\n","\n","#이전에 처리한 이미지 사용\n","img_for_class = img_new_blur.copy()\n","\n","#최종 이미지 파일용 배열\n","new_img = []\n","margin_pixel = margin\n","\n","#숫자영역 추출 및 reshape\n","for rect in rects_new:\n","  im = img_for_class[rect[1]-margin_pixel:rect[1]+rect[3]+margin_pixel, rect[0]-margin_pixel:rect[0]+rect[2]+margin_pixel]\n","  row, col = im.shape[:2]\n","  #정방형 비율 맞추기\n","  bordersize = max(row,col)\n","  diff = min(row,col)\n","  #이미지의 intensity 평균\n","  bottom = im[row-2: row, 0:col]\n","  mean = cv2.mean(bottom)[0]\n","  #정방형 비율로 보정\n","  border = cv2.copyMakeBorder(\n","      im, top =0, bottom =0,\n","      left = int((bordersize - diff) / 2),\n","      right = int ((bordersize - diff) / 2),\n","      borderType = cv2.BORDER_CONSTANT,\n","      value = [255, 255, 255]\n","  )\n","  square = border\n","\n","  #(28,28)로 축소\n","  resized_img = cv2.resize(square, dsize = (28, 28), interpolation = cv2.INTER_AREA)\n","  new_img.append(resized_img)\n"],"metadata":{"id":"bu10JtyV5KKf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res_index2 = []\n","\n","for i in range(len(new_img)):\n","  img2 = new_img[i]\n","  cv2_imshow(img2)\n","  img2 = img2.reshape(-1,28,28,1)\n","  input_data2 = ((np.array(img2) / 255) - 1) * -1\n","  result2 = np.argmax(cnn_model.predict(input_data2), axis = -1)\n","  res_index2.append(int(result2))\n","  print(result2)\n","\n","res_index2 #학번 정수값 리스트"],"metadata":{"id":"XkM3wm-KoV6q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["vector_list2= [] #이미지가 리스트에 저장되어있다.\n","\n","for i in range(9):\n","  b = Image.fromarray(new_img[i])\n","  b.save('nd{0}.jpg'.format(i+1)) \n","  vector_list2.append(b)"],"metadata":{"id":"X3uyrfehD-yD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#유사도 판별"],"metadata":{"id":"s8dN58Tunf__"}},{"cell_type":"code","source":["from google.colab import files\n","vcfile = files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":110},"id":"mVqsIwzQIpmj","executionInfo":{"status":"ok","timestamp":1670846957952,"user_tz":-540,"elapsed":16222,"user":{"displayName":"김산","userId":"17362589598531284018"}},"outputId":"2a2185c2-ee9c-4908-f96b-671f20d4625c"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-6dd2a967-c925-493c-993f-221813449ee9\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-6dd2a967-c925-493c-993f-221813449ee9\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving 김산이름.jpg to 김산이름.jpg\n","Saving 박한성이름.jpg to 박한성이름.jpg\n"]}]},{"cell_type":"code","source":["pic_one_vector = get_vector('파일1') # 벡터 \n","pic_two_vector = get_vector('파일2')"],"metadata":{"id":"Tk737VdaxVIA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using PyTorch Cosine Similarity\n","cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","pic_one_vector = torch.tensor(pic_one_vector)\n","pic_two_vector = torch.tensor(pic_two_vector)\n","cos_sim = cos(pic_one_vector.unsqueeze(0), pic_two_vector.unsqueeze(0))\n","print('\\nCosine similarity: {0}\\n'.format(cos_sim))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KorBsGULIeGT","executionInfo":{"status":"ok","timestamp":1670846976747,"user_tz":-540,"elapsed":8,"user":{"displayName":"김산","userId":"17362589598531284018"}},"outputId":"9a3fef6b-6626-40d6-f8b8-8d8d25a6d97d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Cosine similarity: tensor([0.8537])\n","\n"]}]}]}