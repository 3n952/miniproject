{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#모델 생성"
      ],
      "metadata": {
        "id": "2A5_yUbtLNWH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eGDBZOdcVCT3"
      },
      "outputs": [],
      "source": [
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps    \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#파일 지정, 초기값 설정 \n",
        "class Config():\n",
        "    training_dir = \"파일 경로\"\n",
        "    testing_dir = \"파일 경로\"\n",
        "    train_batch_size = 32\n",
        "    train_number_epochs = 10"
      ],
      "metadata": {
        "id": "6r3z-ZfkVbzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_dir=\"파일 경로\"\n",
        "training_csv=\"파일 경로\"\n",
        "testing_csv=\"파일 경로\"\n",
        "testing_dir=\"파일 경로\""
      ],
      "metadata": {
        "id": "w69Xpy3gVvsT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 시각화를 위한 함수 선언\n",
        "def imshow(img,text=None,should_save=False):\n",
        "    npimg = img.numpy()\n",
        "    plt.axis(\"off\")\n",
        "    if text:\n",
        "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
        "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()    "
      ],
      "metadata": {
        "id": "CfR482boKRyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SiameseNetworkDataset():\n",
        "    \n",
        "    def __init__(self,training_csv=None,training_dir=None,transform=None):\n",
        "        # 이미지, 라벨을 매칭\n",
        "          self.training_df=pd.read_csv(training_csv)\n",
        "          self.training_df.columns =[\"image1\",\"image2\",\"label\"]\n",
        "          self.training_dir = training_dir    \n",
        "          self.transform = transform\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        \n",
        "        # 이미지 저장 경로 \n",
        "        image1_path=os.path.join(self.training_dir,self.training_df.iat[index,0])\n",
        "        image2_path=os.path.join(self.training_dir,self.training_df.iat[index,1])\n",
        "        \n",
        "        \n",
        "        # 이미지 로드\n",
        "        img0 = Image.open(image1_path)\n",
        "        img1 = Image.open(image2_path)\n",
        "        img0 = img0.convert(\"L\")\n",
        "        img1 = img1.convert(\"L\")\n",
        "        \n",
        "        # 이미지 transform\n",
        "        if self.transform is not None:\n",
        "            img0 = self.transform(img0)\n",
        "            img1 = self.transform(img1)\n",
        "        \n",
        "        return img0, img1 , torch.from_numpy(np.array([int(self.training_df.iat[index,2])],dtype=np.float32))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.training_df)"
      ],
      "metadata": {
        "id": "oC0jNvY-WHco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 이미지 파일을 샴네트웨크에 맞게 조정한 데이터 셋\n",
        "siamese_dataset = SiameseNetworkDataset(training_csv,training_dir,transform=transforms.Compose([transforms.Resize((105,105)),transforms.ToTensor()]))\n"
      ],
      "metadata": {
        "id": "YWKPJd_eWK2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샘플 체크 & 라벨링 확인\n",
        "vis_dataloader = DataLoader(siamese_dataset, shuffle=True, batch_size=8)\n",
        "dataiter = iter(vis_dataloader)\n",
        "\n",
        "\n",
        "example_batch = next(dataiter) #data중 하나 샘플로 값 뽑아오기\n",
        "concatenated = torch.cat((example_batch[0],example_batch[1]),0)\n",
        "imshow(torchvision.utils.make_grid(concatenated))\n",
        "print(example_batch[2].numpy())"
      ],
      "metadata": {
        "id": "d1ezW5Y9XQhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model network 만들기\n",
        "class SiameseNetwork(nn.Module): \n",
        "    def __init__(self):\n",
        "        super(SiameseNetwork, self).__init__() #nn.module에 상속 받아 정의 및 초기화\n",
        "        \n",
        "        # cnn layer 구성\n",
        "        self.cnn1 = nn.Sequential(\n",
        "            \n",
        "            nn.Conv2d(1, 96, kernel_size=11,stride=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            \n",
        "            nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.LocalResponseNorm(5,alpha=0.0001,beta=0.75,k=2),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "            nn.Conv2d(256,384 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384,256 , kernel_size=3,stride=1,padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(3, stride=2),\n",
        "            nn.Dropout(p=0.3),\n",
        "\n",
        "        )\n",
        "        \n",
        "        # fc layer 구성\n",
        "        self.fc1 = nn.Sequential(\n",
        "            \n",
        "            nn.Linear(30976, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.5),\n",
        "            \n",
        "            nn.Linear(1024, 128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            \n",
        "            nn.Linear(128,2)) # 자기자신 or 위조\n",
        "        \n",
        "  \n",
        "  \n",
        "    def forward_once(self, x):\n",
        "        # 모델 순전파 방향 흐름\n",
        "        output = self.cnn1(x)\n",
        "        output = output.view(output.size()[0], -1)\n",
        "        output = self.fc1(output)\n",
        "        return output\n",
        "\n",
        "    def forward(self, input1, input2): #유사도 비교를 위한 입력2 출력2\n",
        "        # 순전파 인풋1:아웃풋1\n",
        "        output1 = self.forward_once(input1)\n",
        "        # 순전파 인풋2:아웃풋2\n",
        "        output2 = self.forward_once(input2)\n",
        "        return output1, output2"
      ],
      "metadata": {
        "id": "R1espxFLXV7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContrastiveLoss(torch.nn.Module):#손실함수 정의\n",
        "\n",
        "    def __init__(self, margin=2.0):\n",
        "        super(ContrastiveLoss, self).__init__() #부모 클래스 상속을 위한 초기화\n",
        "        self.margin = margin\n",
        "\n",
        "    def forward(self, output1, output2, label): #순전파 방향의 output으로 손실을 정의, contrastive loss를 손실함수로 사용\n",
        "        euclidean_distance = F.pairwise_distance(output1, output2)\n",
        "        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) + (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))\n",
        "        return loss_contrastive"
      ],
      "metadata": {
        "id": "REGDxoqBv6xw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(siamese_dataset,shuffle=True,num_workers=2,batch_size=Config.train_batch_size)"
      ],
      "metadata": {
        "id": "V9p7YKrZwOPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 샴네트워크모델 선언\n",
        "net = SiameseNetwork().cuda()\n",
        "# 손실함수 선언\n",
        "criterion = ContrastiveLoss()\n",
        "# 옵티마이저 선언\n",
        "optimizer = optim.Adam(net.parameters(), lr=1e-4, weight_decay=0.0001)"
      ],
      "metadata": {
        "id": "ck0puMctwb9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 정확도 측정 함수\n",
        "def getAccuracy():\n",
        "  net.eval()\n",
        "  list_0 = torch.FloatTensor([[0]])\n",
        "  list_1 = torch.FloatTensor([[1]])\n",
        "  acc = 0\n",
        "  total = 0\n",
        "  with torch.no_grad():\n",
        "    for data in train_dataloader:\n",
        "      image1,image2, label = data\n",
        "      output1, output2 = net(image1,image2)\n",
        "      eucledian_distance = F.pairwise_distance(output1, output2)\n",
        "      if eucledian_distance.item() <= 0.8 and label == list_0: #상이도 0.8이하이고 라벨이 0인경우(본인)\n",
        "        acc += 1\n",
        "      elif eucledian_distance.item() > 0.8 and label == list_1: #상이도 0.8이상이고 라벨이 1인경우(위조)\n",
        "        acc += 1\n",
        "      \n",
        "      total += 1\n",
        "\n",
        "  accuracy = (100 * acc / total)\n",
        "  return (accuracy)\n",
        "         \n",
        "      "
      ],
      "metadata": {
        "id": "-UTuPT7D59pL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#훈련 함수 정의\n",
        "def train():\n",
        "  best_accuracy = 0.0\n",
        "\n",
        "  for epoch in range(0,Config.train_number_epochs): \n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    for i, data in enumerate(train_dataloader,0): #인덱스, 데이터 저장\n",
        "      img0, img1 , label = data\n",
        "      img0, img1 , label = img0.cuda(), img1.cuda() , label.cuda()\n",
        "      optimizer.zero_grad() #옵티마이저 파라미터 0으로 초기화\n",
        "      output1,output2 = net(img0,img1) #샴네트워크 모델 순전파 결과\n",
        "      loss_contrastive = criterion(output1,output2,label) #손실 측정\n",
        "      loss_contrastive.backward() #손실함수의 오차역전파(nn.module에서 제공)\n",
        "      optimizer.step()\n",
        "      running_loss += loss_contrastive.item()     # extract the loss value\n",
        "      if i %50 == 49 :\n",
        "        print(\"Epoch:{} loss:{:0.2f}\\n\".format(epoch,loss_contrastive.item()))\n",
        "        running_loss = 0.0\n",
        "\n",
        "    accuracy = getAccuracy()\n",
        "    print('epoch', epoch+1,'일 때 accuracy:%d %%' %(accuracy))\n",
        "    \n",
        "    if accuracy > best_accuracy:\n",
        "      torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/인공지능 기초/model_adam.pt\")\n",
        "      best_accuracy = accuracy"
      ],
      "metadata": {
        "id": "nRCsJ337wn7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cuda 사용확인\n",
        "'''\n",
        "if torch.cuda.is_available():\n",
        "  print('Yes')\n",
        "'''"
      ],
      "metadata": {
        "id": "-1N4VOjEbmQO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train()\n",
        "print(\"학습완료\")"
      ],
      "metadata": {
        "id": "r1yMYgMsbpsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#모델 불러오기"
      ],
      "metadata": {
        "id": "4swCxgVzLKml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torch.utils.data as utils\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader,Dataset\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.utils\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "from torch.optim import lr_scheduler\n",
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import PIL.ImageOps    \n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd "
      ],
      "metadata": {
        "id": "z7gdrQszLRP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 저장\n",
        "torch.save(model.state_dict(), \"저장할 모델 파일 경로\")"
      ],
      "metadata": {
        "id": "Z0n9SJYbKiQ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 불러오기\n",
        "model.load_state_dict(torch.load(\"저장된 모델 파일 경로\"))\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "eFBqOwT6K2g5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 저장된 모델 로드\n",
        "model = SiameseNetwork()\n",
        "# 저장된 모델 파라미터 공유\n",
        "model.load_state_dict(torch.load(\"모델 파일 경로\")) "
      ],
      "metadata": {
        "id": "PT5oBnwR1dNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터 셋 로드\n",
        "test_dataset = SiameseNetworkDataset(training_csv=testing_csv,training_dir=testing_dir,transform=transforms.Compose([transforms.Resize((105,105)),transforms.ToTensor()]))\n",
        "\n",
        "test_dataloader = DataLoader(test_dataset,num_workers=6,batch_size=1,shuffle=True)"
      ],
      "metadata": {
        "id": "maL6uSu_bs5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 이미지별 dissimilarity 비교.\n",
        "counter=0\n",
        "list_0 = torch.FloatTensor([[0]])\n",
        "list_1 = torch.FloatTensor([[1]])\n",
        "for i, data in enumerate(test_dataloader,0): \n",
        "  x0, x1 , label = data\n",
        "  concatenated = torch.cat((x0,x1),0)\n",
        "  output1,output2 = model(x0,x1)\n",
        "  eucledian_distance = F.pairwise_distance(output1, output2)\n",
        "  if label==list_0:\n",
        "    label=\"Orginial\"\n",
        "  else:\n",
        "    label=\"Forged\"\n",
        "  imshow(torchvision.utils.make_grid(concatenated),'Dissimilarity: {:.2f} Label: {}'.format(eucledian_distance.item(),label))\n",
        "  counter=counter+1\n",
        "  if counter == 10:\n",
        "     break"
      ],
      "metadata": {
        "id": "-CkqyTqTbvnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}