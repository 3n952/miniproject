{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#학번 숫자 인식 및 분류"
      ],
      "metadata": {
        "id": "LjAMVCMr8quD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#분류 모델"
      ],
      "metadata": {
        "id": "LR-Frmx8q2AX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "opx0q1cXRXzz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "%matplotlib inline "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
      ],
      "metadata": {
        "id": "89TBSQtpRhai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#랜덤값 고정\n",
        "tf.random.set_seed(1234)\n",
        "\n",
        "#normalize\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# reshape\n",
        "X_train = X_train.reshape(-1, 28, 28, 1)\n",
        "X_test = X_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# one-hot 인코딩\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)"
      ],
      "metadata": {
        "id": "watvOakARkU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 컴파일\n",
        "cnn_model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, input_shape=(28,28,1), padding='same', activation='relu'), \n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=64, padding='same', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=128, input_shape=(28,28,1), padding='same', activation='relu'),\n",
        "    tf.keras.layers.Conv2D(kernel_size=(3,3), filters=256, input_shape=(28,28,1), padding='valid', activation='relu'),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=256, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.5),\n",
        "    tf.keras.layers.Dense(units=10, activation='softmax')\n",
        "])\n",
        "cnn_model.compile(loss='categorical_crossentropy', optimizer= tf.optimizers.Adam(learning_rate=0.001), metrics = ['accuracy'])"
      ],
      "metadata": {
        "id": "HyQuq1Z7RtUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#callback & early stopping 지점, 기준\n",
        "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint('best-model.h5', save_best_only = True)\n",
        "earlystopping_cb = tf.keras.callbacks.EarlyStopping(patience = 2, restore_best_weights=True)\n",
        "\n",
        "#모델 학습 + callback & early stopping\n",
        "history = cnn_model.fit(X_train, y_train, batch_size=100, epochs=20, validation_data=(X_test, y_test), callbacks = [checkpoint_cb, earlystopping_cb])"
      ],
      "metadata": {
        "id": "_eGaNBgVRy4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#callback & early stopping한 지점까지 에포크 단위별 loss 시각화\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend(['train', 'val'])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kx5HipJ7SKcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#모델 정확도 / 그래프 해석 예시: 그래프에서 보이듯이 epoch 5에서 가장 낮은 손실 점수 보여준다. (인덱스0부터 시작이므로 4는 5를 의미)\n",
        "result = cnn_model.evaluate(X_test, y_test)\n",
        "print(\"예측 정확도(%): \", result[1]*100)"
      ],
      "metadata": {
        "id": "g5bK_NOpSawP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#데이터베이스에 넣을 feature_vector값 구하기 (등록)"
      ],
      "metadata": {
        "id": "NEObbmf8Sl5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from PIL import Image\n",
        "\n",
        "# resnet적용\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "# avgpool layer 추출\n",
        "layer = model._modules.get('avgpool')\n",
        "\n",
        "# 평가모드로 전환\n",
        "model.eval()\n",
        "\n",
        "# 이미지 transform\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()\n",
        "\n",
        "#특징 벡터 추출할 함수 선언\n",
        "def get_vector(image_name):\n",
        "  img = Image.open(image_name)\n",
        "  t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)) #이미지 텐서변수에 할당\n",
        "  my_embedding = torch.zeros(512) #특징 벡터가 들어갈 배열 초기화\n",
        "  def copy_data(m, i, o): #특징벡터 복사 함수\n",
        "    my_embedding.copy_(o.data.reshape(o.data.size(1))) \n",
        "  h = layer.register_forward_hook(copy_data) #텐서변수 값 추출\n",
        "  model(t_img) #resnet 모델에 적용\n",
        "  h.remove() #초기화\n",
        "  return my_embedding.numpy() #특징벡터를 넘파이배열로 바꿈\n"
      ],
      "metadata": {
        "id": "WfbW5r7RSuNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학번 정수값 저장"
      ],
      "metadata": {
        "id": "S5Ts6X8oORwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "dbfile = files.upload()"
      ],
      "metadata": {
        "id": "Nzn8XiMprGdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_db = cv2.imread('파일명')\n",
        "\n",
        "\n",
        "img_db_gray = cv2.cvtColor(img_db, cv2.COLOR_BGR2GRAY)\n",
        "img_db_blur = cv2.GaussianBlur(img_db_gray, (5, 5), 0)\n",
        "\n",
        "#이미지 내의 경계 찾기\n",
        "ret_db,img_db_th = cv2.threshold(img_db_blur, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "contours_db, hierachy_db = cv2.findContours(img_db_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "#경계 직사각형 찾기\n",
        "rects_db = [cv2.boundingRect(each) for each in contours_db]\n",
        "rects_db = sorted(rects_db)\n",
        "\n",
        "margin = 8\n",
        "for rect in rects_db:\n",
        "  print(rect)\n",
        "  im1_db = cv2.rectangle(img_db_blur.copy(),(rect[0]-margin,rect[1]-margin),(rect[0]+rect[2]+margin, rect[1]+rect[3]+margin),(0,0,0),3)\n"
      ],
      "metadata": {
        "id": "0Ey1pjtBjDGn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#이전에 처리한 이미지 사용\n",
        "img_for_class = img_db_blur.copy()\n",
        "\n",
        "#최종 이미지 파일용 배열\n",
        "db_img = []\n",
        "margin_pixel = margin\n",
        "\n",
        "#숫자영역 추출 및 reshape\n",
        "for rect in rects_db:\n",
        "  im = img_for_class[rect[1]-margin_pixel:rect[1]+rect[3]+margin_pixel, rect[0]-margin_pixel:rect[0]+rect[2]+margin_pixel]\n",
        "  row, col = im.shape[:2]\n",
        "  #정방형 비율 맞추기\n",
        "  bordersize = max(row,col)\n",
        "  diff = min(row,col)\n",
        "  #이미지의 intensity 평균\n",
        "  bottom = im[row-2: row, 0:col]\n",
        "  mean = cv2.mean(bottom)[0]\n",
        "  #정방형 비율로 보정\n",
        "  border = cv2.copyMakeBorder(\n",
        "      im, top =0, bottom =0,\n",
        "      left = int((bordersize - diff) / 2),\n",
        "      right = int ((bordersize - diff) / 2),\n",
        "      borderType = cv2.BORDER_CONSTANT,\n",
        "      value = [255, 255, 255]\n",
        "  )\n",
        "  square = border\n",
        "\n",
        "  #(28,28)로 축소\n",
        "  resized_img = cv2.resize(square, dsize = (28, 28), interpolation = cv2.INTER_AREA)\n",
        "  db_img.append(resized_img)"
      ],
      "metadata": {
        "id": "D_ZmWWpNnPbo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_index = []\n",
        "\n",
        "for i in range(len(db_img)):\n",
        "  img = db_img[i]\n",
        "  cv2_imshow(img)\n",
        "  img = img.reshape(-1,28,28,1)\n",
        "  input_data = ((np.array(img) / 255) - 1) * -1\n",
        "  result = np.argmax(cnn_model.predict(input_data), axis = -1)\n",
        "  res_index.append(int(result))\n",
        "  print(result)\n",
        "\n",
        "res_index #학번 정수값 리스트"
      ],
      "metadata": {
        "id": "WYbqW6HYEJ9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#학번 번호별 이미지 저장 28*28크기\n",
        "db_img"
      ],
      "metadata": {
        "id": "PA84vGpApyiE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#학번 벡터값 저장"
      ],
      "metadata": {
        "id": "rqrAqZDiOV-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "vector_list1 = [] #이미지가 리스트에 저장되어있다.\n",
        "\n",
        "for i in range(9):\n",
        "  a = Image.fromarray(db_img[i])\n",
        "  a.save('db{0}.jpg'.format(i+1)) \n",
        "  vector_list1.append(a)\n"
      ],
      "metadata": {
        "id": "aK25MYGZOnH8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#new data vector(인식)"
      ],
      "metadata": {
        "id": "HmHfoBiJ5KaA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_new = cv2.imread('파일명')\n",
        "\n",
        "\n",
        "img_new_gray = cv2.cvtColor(img_new, cv2.COLOR_BGR2GRAY)\n",
        "img_new_blur = cv2.GaussianBlur(img_new_gray, (5, 5), 0)\n",
        "\n",
        "#이미지 내의 경계 찾기\n",
        "ret_new,img_new_th = cv2.threshold(img_new_blur, 127, 255, cv2.THRESH_BINARY_INV)\n",
        "contours_new, hierachy_new = cv2.findContours(img_new_th.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
        "\n",
        "#경계 직사각형 찾기\n",
        "rects_new = [cv2.boundingRect(each) for each in contours_new]\n",
        "rects_new = sorted(rects_new)\n",
        "\n",
        "margin = 8\n",
        "for rect in rects_new:\n",
        "  print(rect)\n",
        "  im1_new = cv2.rectangle(img_new_blur.copy(),(rect[0]-margin,rect[1]-margin),(rect[0]+rect[2]+margin, rect[1]+rect[3]+margin),(0,0,0),3)\n",
        "\n",
        "#이전에 처리한 이미지 사용\n",
        "img_for_class = img_new_blur.copy()\n",
        "\n",
        "#최종 이미지 파일용 배열\n",
        "new_img = []\n",
        "margin_pixel = margin\n",
        "\n",
        "#숫자영역 추출 및 reshape\n",
        "for rect in rects_new:\n",
        "  im = img_for_class[rect[1]-margin_pixel:rect[1]+rect[3]+margin_pixel, rect[0]-margin_pixel:rect[0]+rect[2]+margin_pixel]\n",
        "  row, col = im.shape[:2]\n",
        "  #정방형 비율 맞추기\n",
        "  bordersize = max(row,col)\n",
        "  diff = min(row,col)\n",
        "  #이미지의 intensity 평균\n",
        "  bottom = im[row-2: row, 0:col]\n",
        "  mean = cv2.mean(bottom)[0]\n",
        "  #정방형 비율로 보정\n",
        "  border = cv2.copyMakeBorder(\n",
        "      im, top =0, bottom =0,\n",
        "      left = int((bordersize - diff) / 2),\n",
        "      right = int ((bordersize - diff) / 2),\n",
        "      borderType = cv2.BORDER_CONSTANT,\n",
        "      value = [255, 255, 255]\n",
        "  )\n",
        "  square = border\n",
        "\n",
        "  #(28,28)로 축소\n",
        "  resized_img = cv2.resize(square, dsize = (28, 28), interpolation = cv2.INTER_AREA)\n",
        "  new_img.append(resized_img)\n"
      ],
      "metadata": {
        "id": "bu10JtyV5KKf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res_index2 = []\n",
        "\n",
        "for i in range(len(new_img)):\n",
        "  img2 = new_img[i]\n",
        "  cv2_imshow(img2)\n",
        "  img2 = img2.reshape(-1,28,28,1)\n",
        "  input_data2 = ((np.array(img2) / 255) - 1) * -1\n",
        "  result2 = np.argmax(cnn_model.predict(input_data2), axis = -1)\n",
        "  res_index2.append(int(result2))\n",
        "  print(result2)\n",
        "\n",
        "res_index2 #학번 정수값 리스트"
      ],
      "metadata": {
        "id": "XkM3wm-KoV6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vector_list2= [] #이미지가 리스트에 저장되어있다.\n",
        "\n",
        "for i in range(9):\n",
        "  b = Image.fromarray(new_img[i])\n",
        "  b.save('nd{0}.jpg'.format(i+1)) \n",
        "  vector_list2.append(b)"
      ],
      "metadata": {
        "id": "X3uyrfehD-yD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#유사도 판별"
      ],
      "metadata": {
        "id": "s8dN58Tunf__"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pic_one_vector = get_vector('파일1') # 벡터 \n",
        "pic_two_vector = get_vector('파일2')"
      ],
      "metadata": {
        "id": "Tk737VdaxVIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using PyTorch Cosine Similarity\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "pic_one_vector = torch.tensor(pic_one_vector)\n",
        "pic_two_vector = torch.tensor(pic_two_vector)\n",
        "cos_sim = cos(pic_one_vector.unsqueeze(0), pic_two_vector.unsqueeze(0))\n",
        "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
      ],
      "metadata": {
        "id": "KorBsGULIeGT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}